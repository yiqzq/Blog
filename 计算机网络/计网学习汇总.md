# 计网学习汇总

[toc]

## 计网分层模型

**OSI分层 （7层）：** 物理层、数据链路层、网络层、传输层、会话层、表示层、应用层。
**TCP/IP分层（4层）：** 网络接口层、 网际层、运输层、 应用层。
**五层协议 （5层）：** 物理层、数据链路层、网络层、运输层、 应用层。



## 运输层的两种协议

### TCP

**传输控制协议 TCP**（Transmisson Control Protocol）--提供面向连接的，可靠的数据传输服务。

1. TCP 是面向连接的。（就好像打电话一样，通话前需要先拨号建立连接，通话结束后要挂机释放连接）；
2. 每一条 TCP 连接只能有两个端点，每一条TCP连接只能是点对点的（一对一）；
3. TCP 提供可靠交付的服务。通过TCP连接传送的数据，无差错、不丢失、不重复、并且按序到达；
4. TCP 提供全双工通信。TCP 允许通信双方的应用进程在任何时候都能发送数据。TCP 连接的两端都设有发**送缓存和接收缓存**，用来临时存放双方通信的数据；
5. 面向字节流。TCP 中的“流”（Stream）指的是流入进程或从进程流出的字节序列。“面向字节流”的含义是：虽然应用程序和 TCP 的交互是一次一个数据块（大小不等），但 TCP 把应用程序交下来的数据仅仅看成是一连串的无结构的字节流。

### UDP

**用户数据协议 UDP**（User Datagram Protocol）--提供无连接的，尽最大努力的数据传输服务（不保证数据传输的可靠性）

1. UDP 是无连接的；
2. UDP 使用尽最大努力交付，即不保证可靠交付，因此主机不需要维持复杂的链接状态（这里面有许多参数）；
3. UDP 是面向报文的；
4. UDP 没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如 直播，实时视频会议等）；
5. UDP 支持一对一、一对多、多对一和多对多的交互通信；
6. UDP 的首部开销小，只有8个字节，比TCP的20个字节的首部要短。

### TCP面向字节流和UDP面向报文的区别

参考博客:<https://blog.csdn.net/oshirdey/article/details/38467391?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task>

打个比方比喻TCP，你家里有个蓄水池，你可以里面倒水，蓄水池上有个龙头，你可以通过龙头将水池里的水放出来，然后用各种各样的容器装(杯子、矿泉水瓶、锅碗瓢盆)接水。

上面的例子中，往水池里倒几次水和接几次水是没有必然联系的，也就是说你可以只倒一次水，然后分10次接完。另外，水池里的水接多少就会少多少;往里面倒多少水，就会增加多少水，但是不能超过水池的容量，多出的水会溢出。

结合TCP的概念，水池就好比接收缓存，倒水就相当于发送数据，接水就相当于读取数据。好比你通过TCP连接给另一端发送数据，你只调用了一次 write，发送了100个字节，但是对方可以分10次收完，每次10个字节;你也可以调用10次write，每次10个字节，但是对方可以一次就收完。 (假设数据都能到达)但是，你发送的数据量不能大于对方的接收缓存(流量控制)，如果你硬是要发送过量数据，则对方的缓存满了就会把多出的数据丢弃。



UDP和TCP不同，发送端调用了几次write，接收端必须用相同次数的read读完。UDP是基于报文的，在接收的时候，每次最多只能读取一个 报文，报文和报文是不会合并的，如果缓冲区小于报文长度，则多出的部分会被丢弃。也就说，如果不指定MSG_PEEK标志，每次读取操作将消耗一个报文。

#### 原因:

TCP是面向连接的，也就是说，在连接持续的过程中，socket中收到的数据都是由同一台主机发出的(劫持什么的不考虑)，因此，知道保证数据是有序的到达就行了，至于每次读取多少数据自己看着办。

而UDP是无连接的协议，也就是说，只要知道接收端的IP和端口，且网络是可达的，任何主机都可以向接收端发送数据。这时候，如果一次能读取超过一 个报文的数据，则会乱套。比如，主机A向发送了报文P1，主机B发送了报文P2，如果能够读取超过一个报文的数据，那么就会将P1和P2的数据合并在了一 起，这样的数据是没有意义的。

## tcp如何实现可靠性传输

### 为什么要随机选择初始序号

主要是为了安全，不让第三方破坏。

如果不是随机产生初始序列号，黑客将会以很容易的方式获取到你与其他主机之间通信的初始化序列号，并且伪造序列号进行攻击，这已经成为一种很常见的网络攻击手段。

### ACK和ack以及seq的区别

ack是确认号，ACK是6个控制位之一，仅当 ACK=1 时ack字段才有效。建立 TCP 连接后，所有报文段都必须把 ACK 字段置为 1。

seq是数据包本身的序列号，ack是期望对方继续发送的那个数据包的序列号。

### 半连接状态

在service端收到client的SYN报文后，会送一个ACK-SYN报文，然后sevice就会进入半连接状态，等待最后一次握手。每一个半连接状态都会存储在一个队列里面，这时候如果伪造大量IP发送请求，就会导致service瘫痪。

### 为什么需要3次握手

**一句话概括，TCP连接握手，握的是啥？**

**通信双方数据原点的序列号！**

A 代表发送方，B代表了接受方

这也就是说，如果只有2次握手，A和B只有对A的seq达成了共识，但是没有对B的seq达成共识，必须增加第三次握手，才能达到对**通信双方各自的seq都有认知的事实**。

### 为什么握手只要三次，而挥手要四次

因为在握手的时候ACK和SYN在第二次握手的时候是一起传的。但是由于TCP是全双工的，断开连接也是双向的，也就是需要A申请断开连接，B申请断开连接，这样子的两次行为。那么在A发出FIN请求后，B指挥返回ACK，确认收到了A的请求，这个时候A已经不会再发送数据，但是B并没有断开连接，所以B可能还会发送一些数据给A，B发送完之后，B会发送FIN请求，最后需要A会送一个ACK，也就是需要四次挥手。

### 为什么挥手最后客户端需要等待2*MSL

因为A最后发送出去的ACK，可能会因为网络延迟等问题造成丢失。那么如果B没收收到ACK，就会触发超时重传机制，再次给A发送FIN消息。那么A收到后，会重启计时器，然后再次发送ACK报文以确保连接正常断开。假设客户端不等待2MSL，而是在发送完ACK之后直接释放关闭，一但这个ACK丢失的话，服务器就无法正常的进入关闭连接状态。

换个方向来说，如果不等，释放的端口可能会重连刚断开的服务器端口，这样依然存活在网络里的老的TCP报文可能与新TCP连接报文冲突，造成数据冲突，为避免此种情况，需要耐心等待网络老的TCP连接的活跃报文全部死翘翘，2MSL时间可以满足这个需求。

**总的的来说，就两点**

1. **可靠地实现TCP全双工连接的终止**
2. **允许老的重复分节在网络中消逝，防止旧信息出现在新的连接中**

### 四次挥手

![](https://img-blog.csdn.net/20170606084851272?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXpjc3U=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)四次挥手过程:

- 主动关闭连接的一方，调用close()；**协议层发送FIN包**
- **被动关闭的一方收到FIN包后，协议层回复ACK**；然后**被动关闭的一方，进入CLOSE_WAIT状态，**主动关闭的一方等待对方关闭，则进入FIN_WAIT_2状态；此时，主动关闭的一方 等待 被动关闭一方的应用程序，调用close操作
- 被动关闭的一方在完成所有数据发送后，调用close()操作；此时，**协议层发送FIN包给主动关闭的一方，等待对方的ACK，被动关闭的一方进入LAST_ACK状态**；
- **主动关闭的一方收到FIN包，协议层回复ACK**；此时，**主动关闭连接的一方，进入TIME_WAIT状态；而被动关闭的一方，进入CLOSED状态**
- 等待2MSL时间，主动关闭的一方，结束TIME_WAIT，进入CLOSED状态

### 出现大量TIME-WAIT的原因

首先TIME-WAIT的出现在TCP四次挥手过程中主动断开连接一方的一个状态。当客户端创建了许多短连接的时候，那么就会出现很多TIME-WAIT状态。

### 多个进程能否监听同一个端口号？

可以

具体参考博客<https://blog.csdn.net/jiyiqinlovexx/article/details/50959351>

### RST

RST：TCP首部中的6个标志比特之一,表示重置连接、复位连接。

在TCP协议中RST表示复位，用来异常的关闭连接，在TCP的设计中 它是不可或缺的。发送RST包关闭连接时，不必等缓冲区的包都发出去，直接就丢弃缓存区的包发送RST包。而接收端收到RST包后，也不必发送ACK包来确认。

> 出现RST包的原因：

- 服务器端口未打开而客户端来连接时
- 在一个已关闭的SOCKET上收到数据
- 请求超时
- 提前关闭

### 服务端解决TIME_WAIT

服务端为了解决这个TIME_WAIT问题，可选择的方式有三种：

1. 保证由客户端主动发起关闭（即做为B端）

2. 关闭的时候使用RST的方式

- 发送RST包关闭连接时，不必等缓冲区的包都发出去，直接就丢弃缓冲区中的包，发送RST。

- 而接收端收到RST包后，也不必发送ACK包来确认。

  对处于TIME_WAIT状态的TCP允许重用
  
  

3. 还可以通过调整内核参数来解决这个问题，我觉得**开启重用**和**快速回收**比较重要。

net.ipv4.tcp_syncookies = 1 表示开启SYN Cookies。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为0，表示关闭；
net.ipv4.tcp_tw_reuse = 1 表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭；
net.ipv4.tcp_tw_recycle = 1 表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭。
net.ipv4.tcp_fin_timeout 修改系默认的 TIMEOUT 时间

4. 允许 `time_wait` 状态的 socket 被重用

### TCP 协议如何保证可靠传输

**校验和：** TCP 将保持它首部和数据的检验和。

**流量控制：** TCP 连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许发送端发送接收端缓冲区能接纳的据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议。 （TCP 利用滑动窗口实现流量控制）

**停止等待协议** 也是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组。

 **超时重传：** 当 TCP 发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段

**使用拥塞窗口**

 **拥塞控制：** 当网络拥塞时，减少数据的发送。

TCP的拥塞控制采用了四种算法，即 **慢开始** 、 **拥塞避免** 、**快重传** 和 **快恢复**。

**慢开始：** 慢开始算法的思路是当主机开始发送数据时，如果立即把大量数据字节注入到网络，那么可能会引起网络阻塞，因为现在还不知道网络的符合情况。经验表明，较好的方法是先探测一下，即由小到大逐渐增大发送窗口，也就是由小到大逐渐增大拥塞窗口数值。cwnd初始值为1，每经过一个传播轮次，cwnd加倍。、

**拥塞避免：** 拥塞避免算法的思路是让拥塞窗口cwnd缓慢增大，即每经过一个往返时间RTT就把发送方的cwnd加1.

**快重传**要求接收方在收到一个失序的报文段后就立即发出重复确认（为的是使发送方及早知道有报文段没有到达对方），而不要等到自己发送数据时捎带确认。
　　快重传算法规定，发送方只要一连收到3个重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待设置的重传计数器时间到期。

**快恢复**
　　（1）当发送方连续收到三个重复确认，就执行“乘法减小”算法，把慢开始门限ssthresh减半。这是为了预防网络发生拥塞。请注意：接下去不执行慢开始算法。
（2）由于发送方现在认为网络很可能没有发生拥塞，因此与慢开始不同之处是现在不执行慢开始算法（即拥塞窗口cwnd现在不设置为1），而是把cwnd值设置为慢开始门限ssthresh减半后的数值，然后开始执行拥塞避免算法（“加法增大”），使拥塞窗口缓慢地线性增大。

## 在浏览器中输入url地址 ->> 显示主页的过程

1. 浏览器查找输入域名对应的IP地址
   1. 现在本地host查找
   2. 本地DNS解析器缓存中查找
   3. 查询首选DNS服务器（本地DNS服务器）
   4. 如果没有转发模式,就直接请求**根域名服务器**,没有的话,返回一个对应的顶级域名服务器,继续查询,直到找到IP地址
   5. 如果用的是转发模式，此DNS服务器就会把请求转发至上一级DNS服务器，由**上一级服务器进行解析**，上一级服务器如果不能解析，或找根DNS或把转请求转至上上级，以此循环。
2. 根据IP地址，请求建立连接（对于TCP而言）
3. 浏览器发送HTTP请求
4. 服务器相应请求，发送HTML请求
5. 浏览器渲染相应的内容

## 关于HTTP的长短连接

在HTTP/1.0中默认使用短连接。也就是说，客户端和服务器每进行一次HTTP操作，就建立一次连接，任务结束就中断连接。当客户端浏览器访问的某个HTML或其他类型的Web页中包含有其他的Web资源（如JavaScript文件、图像文件、CSS文件等），每遇到这样一个Web资源，浏览器就会重新建立一个HTTP会话。

而从HTTP/1.1起，默认使用长连接，用以保持连接特性。使用长连接的HTTP协议，会在响应头加入这行代码：

```
Connection:keep-alive
```

**而且是需要客户端和服务器端都设置才有效。**
在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的TCP连接不会关闭，客户端再次访问这个服务器时，会继续	用这一条已经建立的连接。Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如Apache）中设定这个时间。实现长连接需要客户端和服务端都支持长连接。

**HTTP的长短连接本质上是TCP的长短连接。**

在建立客户端和服务端的连接之后，完成了一次请求，这时候就会有两种选择，要么是断开连接，要么是保持连接。那么这就对应了TCP的两种连接。

**长连接**可以**省去较多的TCP建立和关闭的操作，减少浪费，节约时间**。

**短连接**对于服务器来说管理较为简单，存在的连接都是有用的连接，不需要额外的控制手段

## 关于长短轮询

**1、短轮询：**
客户端向服务器端发起请求，服务器端立即返回相关信息并且关闭链接。同时客户端再次发起请求，与服务器端建立链接。
优点：后端程序的编写简单
缺点：大部分请求是无用的

**2、长轮询**

与轮询不同的是服务器端会hold住链接，等待有数据的情况下返回并且关闭连接。
区别：服务器端hold住请求，客户端不会再请求数据。
优点：无消息的情况下不会再次发起请求
缺点： 会耗费服务端的性能

**3、总结：**
短轮询和长轮询主要是服务器端的实现方式，如果服务器端挂起请求等待消息则实现长轮询，如果服务器端不管任何条件下都返回数据则为短轮询。这种方式可以称之为编程方式实现短轮询和长轮询。

## 常见的状态码

1xx(临时响应)表示临时响应并需要请求者继续执行操作的状态代码

2xx (成功)表示成功处理了请求的状态代码

3xx (重定向) 表示要完成请求，需要进一步操作。 通常，这些状态代码用来重定向

4xx(请求错误) 这些状态代码表示请求可能出错，妨碍了服务器的处理

5xx(服务器错误)这些状态代码表示服务器在尝试处理请求时发生内部错误。 这些错误可能是服务器本身的错误，而不是请求出错

**常见的**

**200** (成功) 服务器已成功处理了请求。 通常，这表示服务器提供了请求的网页。

201 (已创建) 请求成功并且服务器创建了新的资源。

202 (已接受) 服务器已接受请求，但尚未处理。

300 (多种选择) 针对请求，服务器可执行多种操作。 服务器可根据请求者 (user agent) 选择一项操作，或提供操作列表供请求者选择。

**301** (永久移动) 请求的网页已永久移动到新位置。 服务器返回此响应(对 GET 或 HEAD 请求的响应)时，会自动将请求者转到新位置。

400 (错误请求) 服务器不理解请求的语法。

401 (未授权) 请求要求身份验证。 对于需要登录的网页，服务器可能返回此响应。

**403 (禁止) 服务器拒绝请求。**

**404** (未找到) 服务器找不到请求的网页。

**500** (服务器内部错误) 服务器遇到错误，无法完成请求。

**502** (错误网关) 服务器作为网关或代理，从上游服务器收到无效响应。

**504** (网关超时) 服务器作为网关或代理，但是没有及时从上游服务器收到请求。

## HTTP和HTTPS的区别与联系

HTTP：是互联网上应用最为广泛的一种网络协议，是一个客户端和服务器端请求和应答的标准（TCP），用于从WWW服务器传输超文本到本地浏览器的传输协议，它可以使浏览器更加高效，使网络传输减少。

HTTPS：是以安全为目标的HTTP通道，简单讲是HTTP的安全版，即HTTP下加入SSL层，HTTPS的安全基础是SSL，因此加密的详细内容就需要SSL。

HTTPS和HTTP的区别主要如下：

1、https协议需要到ca申请证书，一般免费证书较少，因而需要一定费用。

2、http是超文本传输协议，信息是明文传输，https则是具有安全性的ssl加密传输协议。

3、http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。

4、http的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。

## Http的请求报文和响应报文

一个HTTP**请求报文**由请求行（request line)，消息头部（header)，空行，请求正文4个部分组成。

1. 请求行由**请求方法**，**URL**，**HTTP协议版本**3个字段组成，它们用空格分隔。
   - 一些请求方法：GET、HEAD、PUT、POST、TRACE、OPTIONS、DELETE
2. 消息头部就是一些键值对，用于通知服务器有关于客户端请求的信息。
3. 空行用来通知以下是请求的正文
4. 请求正文比如post方法就会包含数据

一个HTTP响应报文主要由状态行、响应头部、响应正文3部分组成。

1. 状态行由3部分组成，分别为：协议版本，状态码，状态码描述，之间由空格分隔
2. 响应头部和请求头类似
3. 响应正文就是服务器响应的数据



## HTTPS协议解析

HTTPS协议为了保传输的安全，采用的是对称加密算法（AES）+非对称加密算法（RSA）+散列算法（MD5）的方式加密整个流程。

同时使用CA证书保证了证书的可靠性。证书=服务器公钥+申请者与颁发者信息+签名

下面是一个大概的基本流程。

<img src="https://i.loli.net/2020/04/15/CG8f19wYVdUtOEW.png" alt="image-20200415124610198" style="zoom:80%;" />

1. 客户端请求建立https连接。
2. 服务端会发送自己的CA证书给客户端，这里面包含了服务端的公钥，后于后续对对称加密算法的传递。
3. 客户端会验证这个证书
   1. 首先会验证证书的颁发机构是不是可信任，如果不可信任，就会提示证书的不可信
   2. 如果可信，就会验证数字签名是否一致。首先对传输过来的数字签名使用CA的公钥解密，生成一份消息摘要。
   3. 然后对证书的信息使用哈希算法加密，也生成一份消息摘要，客户端对两份摘要进行对比，如果相同，则认为证书正确。
4. 客户端随机一个数字，作为之后通信的对称算法的密钥，使用服务端的公钥加密密钥，保证这个数字不会被中间截取
5. 服务端收到客户端的信息，使用自己的私钥解密，获得对称算法的密钥。
6. 之后通信双方就会使用对称算法的密钥进行通信，保证了数据的安全性。

下图是数字签名的生成。

<img src="https://i.loli.net/2020/04/15/57gZWoFIGcPUY3j.png" alt="image-20200415130204158" style="zoom:80%;" />

**为什么使用对称算法加密通信数据而不是非对称算法？**

原因是非对称算法性能太低，影响速度。

## CDN介绍

CDN即内容分发网络，是基于用户的地理位置、网页的源地址还有就是一个内容分发服务器。距离CDN服务器越近的用户，就能越快地获取到静态内容。

**CDN缓存后的网站的访问过程**

(1) 用户向浏览器提供要访问的域名；

(2) 浏览器调用域名解析库对域名进行解析得到CNAME，再解析CNAME域名获取IP地址，在此过程中，使用的全局负载均衡DNS解析，如根据地理位置信息解析对应的IP地址，使得用户能就近访问;

(3) 这次解析到只是CDN服务器的IP地址，浏览器获取这个IP地址就向CDN缓存发送请求;

(4) CDN缓存服务器根据浏览器提供的要访问的域名，通过Cache内部专用DNS解析得到此域名的实际IP地址，再由缓存服务器向此实际IP地址提交访问请求,缓存服务器就好像是中间人那样子;

(5) CDN缓存服务器获取内容后，一方面在本地存储，以便客户端下次访问；另外一方面就发送给客户端;

(6) 客户端就把从CDN缓存服务器返回的内容显示，下次访问就直接访问CDN缓存服务器。

**使用CDN的好处**

1. 本地Cache加速，加快访问速度
2. 镜像服务，消除运营商之间互联的瓶颈影响，保证不同网络的用户都能得到良好的访问质量
3. 远程加速，自动选择cache服务器
4. 带宽优化，分担网络流量，减轻压力，
5. 集群抗攻击
6. 节约成本

## UDP如何实现可靠性传输

由于UDP在设计的时候是不可靠的，所以想要实现可靠的传输只能通过上层的应用层来控制。

应用层需要模仿TCP连接时候的可靠方法，比如实现确认机制、重传机制、窗口确认机制。

 目前有如下开源程序利用udp实现了可靠的数据传输。分别为RUDP、RTP、UDT。



## 参考内容

[【面经】计网面试题小结](https://www.nowcoder.com/discuss/266772?type=post&order=time&pos=&page=1)

[HTTP和HTTPS详解](https://juejin.im/post/5af557a3f265da0b9265a498#heading-35)

[谈谈 HTTPS](https://juejin.im/post/59e4c02151882578d02f4aca#heading-10)