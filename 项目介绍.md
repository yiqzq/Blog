# 项目介绍

[toc]

## 防止超卖问题

1. 在数据库层面上，对sql语句做了库存大于0的判断，防止商品超卖，在开启事务的情况下，我认为这也是悲观锁的一种吧，毕竟会使用行锁的x锁。

   同时由于系统规定每人每个商品只能购买一个，所以会生成一个秒杀订单，在秒杀订单中建立了（用户ID，商品ID）的唯一索引，防止同一用户多次购买

   ```
   UPDATE seckill_goods
   SET stock_count = stock_count -1
   WHERE goods_id = #{goodsId} and stock_count > 0
   ```

但是，在高并发的环境下显然是不能高频的访问数据库的，会造成严重的性能问题。需要其他例如缓存的措施来减少数据库的压力。

2. 使用乐观锁来处理，增加一个version字段，每次更新时判断version有没有改变
3. 使用Redis的分布式锁，同时只允许拿到锁的用户访问数据库
   - 使用setnx+expire命令实现，记得使用lua脚本保证原子性
   - 使用set的命令`SET key value[EX seconds][PX milliseconds][NX|XX]`
4. **使用消息队列来处理**


## 项目的优点

1. 使用了一个全局的异常处理器
2. 使用Redis实现了分布式session
3. 使用布隆过滤器过滤前端无效请求
4. 做了接口限流和验证码机制
5. 隐藏了秒杀的地址，反之提前秒杀

## 秒杀项目需要改进的地方

1. 使用nginx负载均衡
2. 开启redis集群
3. 没有分库分表

## 你做过秒杀项目，那秒杀项目有哪些需要考虑的点呢，怎样去解决？

1. 超卖
2. 高并发下数据库的压力
3. 用户的体验

## 那在减库存这一块的解决方案都有哪些呢？

1. 使用redis的decr的原子性操作来预减库存，减少直接访问数据库的压力
2. 预减成功后会加入到消息队列中，之后由消息队列来消费，对数据库进行操作

## 那你说一下Redis分布式锁的底层实现

- 使用setnx+expire命令实现，记得使用lua脚本保证原子性
- 使用set的命令`SET key value[EX seconds][PX milliseconds][NX|XX]`

### 分布式锁带来的问题

1. **锁误删除**

如果线程 A 成功获取到了锁，并且设置了过期时间 30 秒，但线程 A 执行时间超过了 30 秒，锁过期自动释放，此时线程 B 获取到了锁；随后 A 执行完成，线程 A 使用 DEL 命令来释放锁，但此时线程 B 加的锁还没有执行完成，线程 A 实际释放的线程 B 加的锁。

解决办法：可以通过UUID生成每一个线程独有的标识，防止误删

2.  **超时解锁导致并发**

如果线程 A 成功获取锁并设置过期时间 30 秒，但线程 A 执行时间超过了 30 秒，锁过期自动释放，此时线程 B 获取到了锁，线程 A 和线程 B 并发执行。

解决办法：一般可以为获取锁的线程增加守护线程，为将要过期但未释放的锁增加有效时间，也叫看门狗机制

3. **锁不可重入**

   https://segmentfault.com/a/1190000022931307

- 利用ThreadLocal实现，获取锁后将Redis中的value保存在ThreadLocal中，同一线程再次尝试获取锁的时候就先将 ThreadLocal 中的 值 与 Redis 的 value 比较，如果相同则表示这把锁属于该线程，即实现可重入锁。但是这样子实现有一个问题，解锁怎么办？因此，在使用一个Map保存锁重入的次数。`ThreadLocal<Map<String, Integer>>`，其中key可以是锁的名称，value是锁重入次数。

  这种方案有一个问题就在于redis分布式锁是设置了过期时间了的，但是ThreadLocal没有，如果在ThreadLocal设置时间，还会涉及到时间一致性的问题。

- 也可以同时使用Redis的Hash结构保存对象，由于和分布式锁采用同一个redis，那么也就解决了不能设置超时时间的问题。具体操作为先判断有没有相关联的hash结构，如果没有就新建一个，并设置自己的uuid对应的值为1。后续线程进来判断的时候，比较是否有自己的uuid，如果没有，说明当前线程不拥有锁，如果有，就计数器加1。这种方法的难点在于实现比较复杂，需要编写lua脚本。

4. **集群下节点宕机的问题**

   ```
   1、客户端A在master节点拿到了锁。
   2、master节点在把A创建的key写入slave之前宕机了。
   3、slave变成了master节点
   4、B也得到了和A还持有的相同的锁（因为原来的slave里还没有A持有锁的信息）
   ```

   在上述集群的环节下，就会出现两个客户端都有资格操作互斥资源的问题了。为了解决在集群环境下的这个问题，Redis的作者提出了RedLock作为解决方案。

   具体流程如下

   ```
   1、获取当前时间（单位是毫秒）。
   2、轮流用相同的key和随机值在N个节点上请求锁，在这一步里，客户端在每个master上请求锁时，会有一个和总的锁释放时间相比小的多的超时时间。比如如果锁自动释放时间是10秒钟，那每个节点锁请求的超时时间可能是5-50毫秒的范围，这个可以防止一个客户端在某个宕掉的master节点上阻塞过长时间，如果一个master节点不可用了，我们应该尽快尝试下一个master节点。
   3、客户端计算第二步中获取锁所花的时间，只有当客户端在大多数master节点上成功获取了锁（在这里是3个），而且总共消耗的时间不超过锁释放时间，这个锁就认为是获取成功了。
   4、如果锁获取成功了，那现在锁自动释放时间就是最初的锁释放时间减去之前获取锁所消耗的时间。
   5、如果锁获取失败了，不管是因为获取成功的锁不超过一半（N/2+1)还是因为总消耗时间超过了锁释放时间，客户端都会到每个master节点上释放锁，即便是那些他认为没有获取成功的锁。
   ```

   

## 项目中的Redis是怎么用的

1. 实现了一个分布式的session
2. 缓存预热了商品的库存
3. 缓存了验证码信息，个人信息，商品信息，收货地址，还有像配合限流注解使用
4. 使用redis实现了布隆过滤器，用户用户轮询订单查看是否秒杀成功

## 如何获得过期时间

通过ttl 命令

## 如何知道已经过期了还是没过期呢？

-1就是过期了

## 解锁的时候如何保证解的是自己的锁呢

可以通过UUID生成每一个线程独有的标识，解锁只能redis中的信息和自己当前的线程一样时才解锁



## 缓存雪崩，缓存穿透，缓存击穿的解决方案

### 缓存雪崩

缓存雪崩的情况是说，当某一时刻发生大规模的缓存失效的情况，比如你的缓存服务宕机了，会有大量的请求进来直接打到DB上面。

**主要使用以下的三种手段**

1. 使用集群缓存，保证缓存服务的高可用
2. ehcache本地缓存 + Hystrix限流&降级,避免MySQL被打死
3. 开启Redis持久化机制，尽快恢复缓存集群

- 缓存过期时间设置一个随机值，避免同时过期
- redis分布式部署，将热点数据分布在不同的服务器上
- 热点数据不过期
- 设置二级缓存

### 缓存穿透

请求去查询一条压根儿数据库中根本就不存在的数据，也就是缓存和数据库都查询不到这条数据，但是请求每次都会打到数据库上面去。这种查询不存在数据的现象我们称为**缓存穿透**。

1. 缓存空值
2. 布隆过滤器
3. 接口层做数据的校验，拦截一部分非法请求，比如id<0


### 缓存击穿

在平常高并发的系统中，大量的请求同时查询一个 key 时，此时这个key正好失效了，就会导致大量的请求都打到数据库上面去。这种现象我们称为**缓存击穿**。

1. 使用互斥锁
2. 考虑热点数据不过期

## 秒杀项目中缓存预热

预热了商品的库存

## 限流设置

自定义了限流注解，默认为一个用户对于同一个接口5秒内最多访问5次

```java
if (cnt == null) {
	RedisUtil.set(key, 1, sec);
} else if (cnt < limit) {
	RedisUtil.incr(key, 1);
}
```



## rabbitmq的用途，用户什么时候才知道订单下成功了

rabbitmq主要用于单线程消费用户的秒杀请求。

用户在前端会隔200ms轮询一次，查看是否能够得到订单ID，如果就会得到提示消息。



## 为什么要用消息队列

异步下单，提高用户体验，把用户秒杀信息存到消息队列中然后用单线程消费防止超卖

## 我看你项目是秒杀系统，你这个数据库是你设计的吗?有哪几张表?

用户表，收货地址，商品表，秒杀商品表，订单表，秒杀订单

## 订单表里面有哪些字段？哪些字段加了索引?

订单id，用户id，商品id，地址id，支付价格，购买数量，订单创建日期，订单状态，还有一些商品的基本信息（名称，图片，购买渠道）

对地址表的用户id建立了索引，对订单表中的用户id建立了索引。

主要是有通过用户id去查询整个订单的sql语句和通过用户id查询地址表的sql语句。

## **我看你用了Redis，怎么保证数据一致性的?**

在高并发的业务场景下，数据库大多数情况都是用户并发访问最薄弱的环节。所以，就需要使用redis做一个缓冲操作，让请求先访问到redis，而不是直接访问Mysql等数据库。这样可以大大缓解数据库的压力。

读取缓存步骤一般没有什么问题，但是一旦涉及到数据更新：数据库和缓存更新，就容易出现缓存和数据库间的数据一致性问题。不管是先写数据库，再删除缓存；还是先删除缓存，再写库，都有可能出现数据不一致的情况。

1. 如果删除了缓存Redis，还没有来得及写库MySQL，另一个线程就来读取，发现缓存为空，则去数据库中读取数据写入缓存，此时缓存中为脏数据。

2. 如果先写了库，在删除缓存前，写库的线程宕机了，没有删除掉缓存，则也会出现数据不一致情况。

一般来说,以mysql中的数据为准，所以对于写操作来说，都是**先更新数据库，然后删除缓存。**

但是，上面也提到了，同样有数据库更新成功，缓存更新失败的可能性。所以有以下的方案可以执行（注意想要保持强一致性是不可能的，如果要强一致性就加锁降低性能，一般都是保持最终一致性）

- 设置缓存过期时间，保持最终一致性

- 把删除动作放到消息队列中，尝试删除，确保缓存删除成功

- 异步方案，通过监听数据库的binlog的变化来删除缓存

- 还有一种方案就是延时双删

  ```
  redes.del(key);
  db.update(data);
  Thread.sleep(2000);
  redes.del(key);
  ```

  

## 如果秒杀缓存减成功，但是mq下单失败，怎么做？把库存加回来吗？

我这里不存在这个问题。单一线程去处理消息队列，每次处理是一个事务，如果失败就会回滚。

## 消息队列为什么用rabbitMQ？

https://juejin.im/post/5dcbbd635188250cd214f817

消息队列有解耦，异步，削峰的作用。我这里主要采用的是异步下单的作用。

**优点**：解耦、异步、削峰
**缺点**：

- 系统可用性降低

- 系统复杂度提高

- 一致性问题

**rabbitmq的六种工作模式**

简单模式、工作队列模式、发布/订阅模式、路由模式、主题模式 和 RPC 模式。

简单模式：单对单

工作队列：多个线程抢占消费一个队列

发布/订阅：用到了fanout 交换机

路由模式：用到了direct交换机

主题模式 ：用到了topic模式

RPC 模式：

**rabbitmq的四种交换机**

- direct（直连交换机）：将队列绑定到交换机，消息的 routeKey 需要与队列绑定的 routeKey 相同。

- fanout （扇形交换机）：不处理 routeKey ，直接把消息转发到与其绑定的所有队列中。

- topic（主题交换机）：根据一定的规则，根据 routeKey 把消息转发到符合规则的队列中，其中 # 用于匹配符合一个或者多个词（范围更广）， * 用于匹配一个词。

- headers （头部交换机）：根据消息的 headers 转发消息而不是根据 routeKey 来转发消息, 其中 header 是一个 Map，也就意味着不仅可以匹配字符串类型，也可以匹配其他类型数据。 规则可以分为所有键值对匹配或者单一键值对匹配。

**和其他消息队列的区别**

| 特性                     | ActiveMQ                              | RabbitMQ                                           | RocketMQ                                                     | Kafka                                                        |
| ------------------------ | ------------------------------------- | -------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 单机吞吐量               | 万级，比 RocketMQ、Kafka 低一个数量级 | 同 ActiveMQ                                        | 10 万级，支撑高吞吐                                          | 10 万级，高吞吐，一般配合大数据类的系统来进行实时数据计算、日志采集等场景 |
| topic 数量对吞吐量的影响 |                                       |                                                    | topic 可以达到几百/几千的级别，吞吐量会有较小幅度的下降，这是 RocketMQ 的一大优势，在同等机器下，可以支撑大量的 topic | topic 从几十到几百个时候，吞吐量会大幅度下降，在同等机器下，Kafka 尽量保证 topic 数量不要过多，如果要支撑大规模的 topic，需要增加更多的机器资源 |
| 时效性                   | ms 级                                 | 微秒级，这是 RabbitMQ 的一大特点，延迟最低         | ms 级                                                        | 延迟在 ms 级以内                                             |
| 可用性                   | 高，基于主从架构实现高可用            | 同 ActiveMQ                                        | 非常高，分布式架构                                           | 非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用 |
| 消息可靠性               | 有较低的概率丢失数据                  | 基本不丢                                           | 经过参数优化配置，可以做到 0 丢失                            | 同 RocketMQ                                                  |
| 功能支持                 | MQ 领域的功能极其完备                 | 基于 erlang 开发，并发能力很强，性能极好，延时很低 | MQ 功能较为完善，还是分布式的，扩展性好                      | 功能较为简单，主要支持简单的 MQ 功能，在大数据领域的实时计算以及日志采集被大规模使用 |



## 大量用户同一时间秒杀商品，如果一个用户不停点击执行秒杀，怎么保证只秒杀一次(不从前端锁定按钮）

对于同一个用户id进行记录限制，在service层就拦截处理掉这个请求。

## 项目里的秒杀系统怎么设计的



展示秒杀商品-》用户选择-》 购买页面-》时间不到前端不开放接口-》验证码购买-》后端会校验时间-》redis预减库存-》写入消息队列-》

## 用到的设计模式

策略

